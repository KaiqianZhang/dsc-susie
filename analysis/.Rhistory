for (i in 1:activeK){
cluster_index = which(kmeans_init$cluster == i)
cluster_index = as.vector(cluster_index)
kth_cluster_data = my_data[cluster_index,]
sigma_list[[i]] = cov(kth_cluster_data)
mu_list[[i]] = mu_init_Mat[i,]
}
# Initial posterior Z-label matrix
membership = postProb(my_data, pi, mu_list, sigma_list)
N = rowSums(membership) # record n_k in each cluster
print('Initial assignment:')
print(N)
# Identify active clusters so far (i.e: which clusters have more than one element, update only those)
activeK_index = which(N>1)
for (s in 1:rep){
pi = stick(activeK,1,N) # prior
membership = postProb(my_data, pi, mu_list, sigma_list)
N = rowSums(membership)
for (k in 1:activeK){
if(N[k]>0){
k_cluster_index = which(membership[k,] %in% 1)
subsetData = my_data[k_cluster_index,]
mu_k = updateMu(p, subsetData, N[k], mu_0, lambda, sigma_list[[k]])
sigma_k = updateSigma(p, subsetData, N[k], nu, psi, lambda, mu_0)
mu_list[[k]] = mu_k
sigma_list[[k]] = sigma_k
}else{
mu_list[[k]] = mu_0
sigma_list[[k]] = sigma_0
}
}
}
valid_group_index = which(N>0)
final_mu_list = mu_list[valid_group_index]
final_sigma_list = sigma_list[valid_group_index]
groupings = c(1:activeK)%*%membership
print('Final assignment: ')
print(N)
return(list('mu'=final_mu_list, 'sigma' = final_sigma_list, 'pi' = pi, 'membership' = groupings))
}
result = Gibbs(Data, activeK=20, rep=300, nu=12, psi=diag(10,10), mu_0=rep(0,10), sigma_0=diag(10,10), lambda=1)
set.seed(12345)
mu1 = runif(10, -1, 0)
mu2 = runif(10, 5, 7)
mu3 = runif(10, 0, 5)
mu4 = runif(10, -5, 0)
mu5 = runif(10, 10, 15)
mu6 = runif(10, -5, 5)
Sigma1 = rWishart(1, 15, diag(1/15, 10))[,,1]
Sigma2 = rWishart(1, 15, diag(1/15, 10))[,,1]
Sigma3 = rWishart(1, 15, diag(1/15, 10))[,,1]
Sigma4 = rWishart(1, 15, diag(1/15, 10))[,,1]
Sigma5 = rWishart(1, 15, diag(1/15, 10))[,,1]
Sigma6 = rWishart(1, 15, diag(1/15, 10))[,,1]
Data = rbind(mvrnorm(50, mu1, Sigma1),
mvrnorm(25, mu2, Sigma2),
mvrnorm(100, mu3, Sigma3),
mvrnorm(50, mu4, Sigma4),
mvrnorm(50, mu5, Sigma5),
mvrnorm(25, mu6, Sigma6))
library(mvtnorm)
library(MASS)
library(MCMCpack)
set.seed(12345)
mu1 = runif(10, -1, 0)
mu2 = runif(10, 5, 7)
mu3 = runif(10, 0, 5)
mu4 = runif(10, -5, 0)
mu5 = runif(10, 10, 15)
mu6 = runif(10, -5, 5)
Sigma1 = rWishart(1, 15, diag(1/15, 10))[,,1]
Sigma2 = rWishart(1, 15, diag(1/15, 10))[,,1]
Sigma3 = rWishart(1, 15, diag(1/15, 10))[,,1]
Sigma4 = rWishart(1, 15, diag(1/15, 10))[,,1]
Sigma5 = rWishart(1, 15, diag(1/15, 10))[,,1]
Sigma6 = rWishart(1, 15, diag(1/15, 10))[,,1]
Data = rbind(mvrnorm(50, mu1, Sigma1),
mvrnorm(25, mu2, Sigma2),
mvrnorm(100, mu3, Sigma3),
mvrnorm(50, mu4, Sigma4),
mvrnorm(50, mu5, Sigma5),
mvrnorm(25, mu6, Sigma6))
stick <- function(activeK, alpha, N){
pi = rep(0, activeK)
beta_vec = rep(0, activeK)
for (k in 1:activeK){
beta_vec[k] = rbeta(1,1+N[k], alpha+sum(N[k:activeK])-N[k])
}
pi[1] = beta_vec[1]
for (i in 2:activeK){
pi[i] = beta_vec[i]*prod(1-beta_vec[1:(i-1)])
}
pi
}
postProb <- function(my_data, pi, mu_list, sigma_list){
activeK = length(mu_list)
temp = pi
post_pi = rep(0, length(pi))
class_assignments = matrix(0, activeK, dim(my_data)[1])
for (i in 1:dim(my_data)[1]){
for (k in 1:activeK){
mu_temp = mu_list[[k]]
sigma_temp = sigma_list[[k]]
temp[k] = pi[k]*dmvnorm(my_data[i,], mu_temp, sigma_temp)
}
post_pi = temp/sum(temp)
Z = match(1, rmultinom(1, 1, post_pi))
class_assignments[,i] = 0
class_assignments[Z,i] = 1
}
class_assignments
}
updateMu <- function(p, subsetData, n_k, mu_0, lambda, sigma_k){
if(length(subsetData)==p){
xbar = subsetData
}else{
xbar = colMeans(subsetData)
}
mumean = (mu_0*lambda+n_k*xbar)/(lambda+n_k)
muvar = 1/(lambda+n_k)*sigma_k
res = mvrnorm(1, mumean, muvar)
res
}
updateSigma <- function(p, subsetData, n_k, nu, psi, lambda, mu_0){
first = nu + n_k
if(length(subsetData)==p){
xbar = subsetData
second = psi + (lambda*n_k)/(lambda+n_k)*(xbar-mu_0)%*%t(xbar-mu_0)
riwish(first, second)
}else{
xbar = colMeans(subsetData)
ret = 0
for (i in 1:n_k){
temp = subsetData[i,]-xbar
ret = ret + temp %*% t(temp)
}
second = psi + ret + (lambda*n_k)/(lambda+n_k)*(xbar-mu_0)%*%t(xbar-mu_0)
riwish(first, second)
}
}
Gibbs <- function(my_data, activeK, rep, nu, psi, mu_0, sigma_0, lambda){
# Set-up
p = ncol(my_data)
pi = rep(1/activeK, activeK) # prior set-up
mu_list = vector('list', activeK) # likelihood set-up
sigma_list = vector('list', activeK)
# Initialization
kmeans_init = kmeans(my_data, activeK) # kmeans initialize mu and sigma
mu_init_Mat = kmeans_init$centers
for (i in 1:activeK){
cluster_index = which(kmeans_init$cluster == i)
cluster_index = as.vector(cluster_index)
kth_cluster_data = my_data[cluster_index,]
sigma_list[[i]] = cov(kth_cluster_data)
mu_list[[i]] = mu_init_Mat[i,]
}
# Initial posterior Z-label matrix
membership = postProb(my_data, pi, mu_list, sigma_list)
N = rowSums(membership) # record n_k in each cluster
print('Initial assignment:')
print(N)
# Identify active clusters so far (i.e: which clusters have more than one element, update only those)
activeK_index = which(N>1)
for (s in 1:rep){
pi = stick(activeK,1,N) # prior
membership = postProb(my_data, pi, mu_list, sigma_list)
N = rowSums(membership)
for (k in 1:activeK){
if(N[k]>0){
k_cluster_index = which(membership[k,] %in% 1)
subsetData = my_data[k_cluster_index,]
mu_k = updateMu(p, subsetData, N[k], mu_0, lambda, sigma_list[[k]])
sigma_k = updateSigma(p, subsetData, N[k], nu, psi, lambda, mu_0)
mu_list[[k]] = mu_k
sigma_list[[k]] = sigma_k
}else{
mu_list[[k]] = mu_0
sigma_list[[k]] = sigma_0
}
}
}
valid_group_index = which(N>0)
final_mu_list = mu_list[valid_group_index]
final_sigma_list = sigma_list[valid_group_index]
groupings = c(1:activeK)%*%membership
print('Final assignment: ')
print(N)
return(list('mu'=final_mu_list, 'sigma' = final_sigma_list, 'pi' = pi, 'membership' = groupings))
}
result = Gibbs(Data, activeK=20, rep=300, nu=12, psi=diag(10,10), mu_0=rep(0,10), sigma_0=diag(10,10), lambda=1)
result$mu
result$sigma
result$mu
set.seed(12345)
mu1 = runif(10, -1, 0)
mu2 = runif(10, 5, 7)
mu3 = runif(10, 0, 5)
mu4 = runif(10, -5, 0)
mu5 = runif(10, 10, 15)
mu6 = runif(10, 15, 20)
Sigma1 = rWishart(1, 15, diag(1/15, 10))[,,1]
Sigma2 = rWishart(1, 15, diag(1/15, 10))[,,1]
Sigma3 = rWishart(1, 15, diag(1/15, 10))[,,1]
Sigma4 = rWishart(1, 15, diag(1/15, 10))[,,1]
Sigma5 = rWishart(1, 15, diag(1/15, 10))[,,1]
Sigma6 = rWishart(1, 15, diag(1/15, 10))[,,1]
Data = rbind(mvrnorm(50, mu1, Sigma1),
mvrnorm(25, mu2, Sigma2),
mvrnorm(100, mu3, Sigma3),
mvrnorm(50, mu4, Sigma4),
mvrnorm(50, mu5, Sigma5),
mvrnorm(25, mu6, Sigma6))
stick <- function(activeK, alpha, N){
pi = rep(0, activeK)
beta_vec = rep(0, activeK)
for (k in 1:activeK){
beta_vec[k] = rbeta(1,1+N[k], alpha+sum(N[k:activeK])-N[k])
}
pi[1] = beta_vec[1]
for (i in 2:activeK){
pi[i] = beta_vec[i]*prod(1-beta_vec[1:(i-1)])
}
pi
}
postProb <- function(my_data, pi, mu_list, sigma_list){
activeK = length(mu_list)
temp = pi
post_pi = rep(0, length(pi))
class_assignments = matrix(0, activeK, dim(my_data)[1])
for (i in 1:dim(my_data)[1]){
for (k in 1:activeK){
mu_temp = mu_list[[k]]
sigma_temp = sigma_list[[k]]
temp[k] = pi[k]*dmvnorm(my_data[i,], mu_temp, sigma_temp)
}
post_pi = temp/sum(temp)
Z = match(1, rmultinom(1, 1, post_pi))
class_assignments[,i] = 0
class_assignments[Z,i] = 1
}
class_assignments
}
updateMu <- function(p, subsetData, n_k, mu_0, lambda, sigma_k){
if(length(subsetData)==p){
xbar = subsetData
}else{
xbar = colMeans(subsetData)
}
mumean = (mu_0*lambda+n_k*xbar)/(lambda+n_k)
muvar = 1/(lambda+n_k)*sigma_k
res = mvrnorm(1, mumean, muvar)
res
}
updateSigma <- function(p, subsetData, n_k, nu, psi, lambda, mu_0){
first = nu + n_k
if(length(subsetData)==p){
xbar = subsetData
second = psi + (lambda*n_k)/(lambda+n_k)*(xbar-mu_0)%*%t(xbar-mu_0)
riwish(first, second)
}else{
xbar = colMeans(subsetData)
ret = 0
for (i in 1:n_k){
temp = subsetData[i,]-xbar
ret = ret + temp %*% t(temp)
}
second = psi + ret + (lambda*n_k)/(lambda+n_k)*(xbar-mu_0)%*%t(xbar-mu_0)
riwish(first, second)
}
}
Gibbs <- function(my_data, activeK, rep, nu, psi, mu_0, sigma_0, lambda){
# Set-up
p = ncol(my_data)
pi = rep(1/activeK, activeK) # prior set-up
mu_list = vector('list', activeK) # likelihood set-up
sigma_list = vector('list', activeK)
# Initialization
kmeans_init = kmeans(my_data, activeK) # kmeans initialize mu and sigma
mu_init_Mat = kmeans_init$centers
for (i in 1:activeK){
cluster_index = which(kmeans_init$cluster == i)
cluster_index = as.vector(cluster_index)
kth_cluster_data = my_data[cluster_index,]
sigma_list[[i]] = cov(kth_cluster_data)
mu_list[[i]] = mu_init_Mat[i,]
}
# Initial posterior Z-label matrix
membership = postProb(my_data, pi, mu_list, sigma_list)
N = rowSums(membership) # record n_k in each cluster
print('Initial assignment:')
print(N)
# Identify active clusters so far (i.e: which clusters have more than one element, update only those)
activeK_index = which(N>1)
for (s in 1:rep){
pi = stick(activeK,1,N) # prior
membership = postProb(my_data, pi, mu_list, sigma_list)
N = rowSums(membership)
for (k in 1:activeK){
if(N[k]>0){
k_cluster_index = which(membership[k,] %in% 1)
subsetData = my_data[k_cluster_index,]
mu_k = updateMu(p, subsetData, N[k], mu_0, lambda, sigma_list[[k]])
sigma_k = updateSigma(p, subsetData, N[k], nu, psi, lambda, mu_0)
mu_list[[k]] = mu_k
sigma_list[[k]] = sigma_k
}else{
mu_list[[k]] = mu_0
sigma_list[[k]] = sigma_0
}
}
}
valid_group_index = which(N>0)
final_mu_list = mu_list[valid_group_index]
final_sigma_list = sigma_list[valid_group_index]
groupings = c(1:activeK)%*%membership
print('Final assignment: ')
print(N)
return(list('mu'=final_mu_list, 'sigma' = final_sigma_list, 'pi' = pi, 'membership' = groupings))
}
install.packages('rmarkdown')
install.packages("rmarkdown")
library(Matrix)
library(susieR)
create_sparsity_mat = function(sparsity, n, p){
nonzero = round(n*p*(1-sparsity))
nonzero.idx = sample(n*p, nonzero)
mat = numeric(n*p)
mat[nonzero.idx] = 1
mat = matrix(mat, nrow=n, ncol=p)
return(mat)
}
set.seed(1)
n = 1000
p = 10000
beta = rep(0,p)
beta[1]    = 10
beta[300]  = 10
beta[400]  = 10
beta[1000] = 10
X.dense = create_sparsity_mat(0.99,n,p)
X.sparse = as(X.dense,'dgCMatrix')
y = c(X.dense %*% beta + rnorm(n))
library(glmnet)
install.packages('glmnet')
library(glmnet)
install.packages('glmnet')
library(Matrix)
library(susieR)
library(glmnet)
create_sparsity_mat = function(sparsity, n, p){
nonzero = round(n*p*(1-sparsity))
nonzero.idx = sample(n*p, nonzero)
mat = numeric(n*p)
mat[nonzero.idx] = 1
mat = matrix(mat, nrow=n, ncol=p)
return(mat)
}
set.seed(1)
n = 1000
p = 10000
beta = rep(0,p)
beta[1]    = 10
beta[300]  = 10
beta[400]  = 10
beta[1000] = 10
X.dense = create_sparsity_mat(0.99,n,p)
X.sparse = as(X.dense,'dgCMatrix')
y = c(X.dense %*% beta + rnorm(n))
glm.fit = cv.glmnet(X.dense,y)
betas = coef(glm.fit, s='lambda.min')
betas
which(betas!=0)
which(betas!=0)[-1]
which(betas!=0)[-1]-1
betas.val = betasp[which(betas!=0)[-1]]
betas.val = betas[which(betas!=0)[-1]]
betas.val
susie.fit = susie(X.dense,y)
library(susieR)
devtools::install_github("stephenslab/susieR")
library(susieR)
susie.fit = susie(X.dense,y)
sets = susie_get_CS(susie.fit, X.dense)
sets$cs
sets$cs_index
pip = susie_get_PIP(susie.fit, sets$cs_index)
pip
pip[sets$cs[[1]]]
sets$cs_index
length(sets$cs)
lapply(length,cs)
cs = sets$cs
lapply(length,cs)
lapply(cs,length)
lista = list()
lista[[1]] = c(1,2,3)
lista[[2]] = c(1)
lista[[3]] = c(1,24,5,6)
lista
lapply(lista, length)
median(lapply(lista, length))
median(sapply(lista, length))
cs[[2]]
pip[400]
a = c(100, 400, 20)
which(max(pip[a]))
which.max(pip[a])
is.list(cs)
is.list(a)
setwd("~/Desktop/M/M-projects/variable_selection_celltype_project/analysis")
X.wbbr = readRDS(wbbr_test_X.rds)
X.wbbr = readRDS('wbbr_test_X.rds')
dim(X.wbbr)
y.wbbr = readRDS('wbbr_test_y.rds')
sum(y.wbbr)
1214-775
setwd("~/Desktop/M/M-github-repos/dsc-susie-2.0/modules")
setwd("~/Desktop/M/M-github-repos/dsc-susie-2.0/analysis")
readRDS('dscout_Q1.rds')
dscout_Q1 = readRDS('dscout_Q1.rds')
View(dscout_Q1)
name(dscout_Q1)
names(dscout_Q1)
install.packages(c('repr', 'IRdisplay', 'evaluate', 'crayon', 'pbdZMQ', 'devtools', 'uuid', 'digest'))
devtools::install_github('IRkernel/IRkernel')
install.packages(c("repr", "IRdisplay", "evaluate", "crayon", "pbdZMQ", "devtools", "uuid", "digest"))
install.packages(c('repr', 'IRdisplay', 'evaluate', 'crayon', 'pbdZMQ', 'devtools', 'uuid', 'digest'))
install.packages(c("repr", "IRdisplay", "evaluate", "crayon", "pbdZMQ", "devtools", "uuid", "digest"))
IRkernel::installspec()
dscout_Q1$sim_gaussian.effect_num
names(dscout_Q1)
dscout_Q1$sim_gaussian.output.file
dscout_Q1$sim_gaussian.output.file
median(c(1,2,3))
create_sparsity_mat = function(sparsity, n, p){
nonzero = round(n*p*(1-sparsity))
nonzero.idx = sample(n*p, nonzero)
mat = numeric(n*p)
mat[nonzero.idx] = 1
mat = matrix(mat, nrow=n, ncol=p)
return(mat)
}
set.seed(1)
n = 1000
p = 10000
beta = rep(0,p)
beta[1]    = 10
beta[300]  = 10
beta[400]  = 10
beta[1000] = 10
X.dense = create_sparsity_mat(0.99,n,p)
fit = susie(X.dense,y)
cs = susie_get_CS(fit, X.dense)
cs_medianSize = median(sapply(cs,length))
cs_medianSize
class(cs_medianSize)
a =1
class(a)
as.numeric(cs_medianSize)
cs_medianSize
length(cs)
class(length(cs))
a = 2.0000000006
round(a,2)
fit= susie(X.dense,y)
susie_get_CS(fit, X.dense)
beta.idx = c(1,3,5)
dense.X[,beta.idx]
effectX = X.dense[,beta.idx]
effectX
cor(effectX)
lower.tri(cor(effectX))
cor(effectX)[lower.tri(cor(effectX))]
cor(c(1,2,3))
cor(as.matrix(c(1,2,3),ncol=1))
lower.tri(cor(as.matrix(c(1,2,3),ncol=1)))
a = c(1,2,3,4,0,0)
a = c(2,2,2,2,0,0)
mean(a[a!=0)]
mean(a[a!=0])
a = c(1,2,3,NA)
mean(a)
mean(a, na.rm=TRUE)
a[is.na(a)]=0
a
getwd()
dscout_large = readRDS('dscout_large.rds')
names(dscout_large)
dscout_large$susie_large.fit
dscout_large$susie_large.fit[10]
class(dscout_large$susie_large.fit[10])
class(dscout_large$susie_large.output.file[10])
dscout_large$susie_large.output.file[10]
open(dscout_large$susie_large.output.file[10])
readRDS(dscout_large$susie_large.output.file[10])
readRDS(dscout_large$susie_large.fit[10])
large_fit = readRDS('compute_beta_sigma_15_sim_gaussian_large_15_susie_large_2')
large_fit = readRDS('compute_beta_sigma_15_sim_gaussian_large_15_susie_large_2.rds')
class(large_fit)
large_fit$num_iter
library(susieR)
susie_iterplot(large_fit, 3, 'demo')
install.packages('reshape')
library(reshape)
susie_iterplot(large_fit, 3, 'demo')
large_fit$cs
large_fit$sets
large_fit$fit
susie_iterplot(large_fit$fit, 3, 'demo')
library(ggplot2)
install.packages('ggplot2')
library(ggplot2)
